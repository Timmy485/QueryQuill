{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d0254a",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e563708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the content of the uploaded file\n",
    "\n",
    "with open(\"../Legal_Files/Corpus/kwame-legal-EL-1680770407105_Technical.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15dd5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__section__\\nJUDGMENT\\n\\n__paragraph__\\nR.C. OWUSU, JA:\\n\\n__paragraph__\\nThis is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast.\\n\\n__paragraph__\\nThe appellant herein had been charge on two counts of careless driving contrary to Sec. 18(1) of R.T.O. 55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29).\\n\\n__paragraph__\\nHe was arraigned before the Community Tribunal, Elmina in the Central Region, tried and found guilty on both Counts. He was convicted on both counts and sentenced to a fine of �200,000.00 or 4 months I.H.L in default. He paid the fine.\\n\\n__paragraph__\\nDissatisfied with the conviction and sentence however, he appealed to the Regional Tribunal, Cape Coast on the grounds that:\\n\\n__paragraph__\\ni. “The Judgment'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a163c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JUDGMENT\\n\\n__paragraph__\\nR.C. OWUSU, JA:\\n\\n__paragraph__\\nThis is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast.\\n\\n__paragraph__\\nThe appellant herein had been charge on two counts of careless driving contrary to Sec. 18(1) of R.T.O. 55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29).\\n\\n__paragraph__\\nHe was arraigned before the Community Tribunal, Elmina in the Central Region, tried and found guilty on both Counts. He was convicted on both counts and sentenced to a fine of �200,000.00 or 4 months I.H.L in default. He paid the fine.\\n\\n__paragraph__\\nDissatisfied with the conviction and sentence however, he appealed to the Regional Tribunal, Cape Coast on the grounds that:\\n\\n__paragraph__\\ni. “The Judgment is not supported by the evidence on record.\\n\\n__paragraph__\\nii. The trial Court Erred in holding that the point of impact was in the lane of traffic of PW1.\\n\\n__paragraph__\\niii. The trial court failed to appreciate the defence of the Accused.\\n\\n__paragraph__\\niv. The trial court failed to adequately evaluate the evidence on record.\\n\\n__paragraph__\\nv. The trial court failed to consider the fact that the 3rd party by driving into the lane of the Accused at a short distance placed the Accused in extreme peril and that which the Accused did or omitted to do in the agony of the moment cannot fairly be treated as negligence.\\n\\n__paragraph__\\nvi. The reasons adduced by the trial court for the rejection of the evidence of Dw1 are untenable in law.\\n\\n__paragraph__\\nvii. The trial court erred palpably in holding that the duty of avoidance of collision was on the Accused and not the third party vehicle which was doing the overtaking.\\n\\n__paragraph__\\nviii. The court failed to appreciate the burden of proof placed on the prosecution and thereby erroneously shifted that burden onto the accused to prove his innocence.\\n\\n__paragraph__\\nix. The trial court failed to consider the issues raised in the address submitted by counsel on behalf of the accused.\\n\\n__paragraph__\\nx. Additional grounds of appeal will be filed upon receipt of the record of appeal.\\n\\n__paragraph__\\nHis appeal was disallowed by the Regional Tribunal. It is against the decision of the Regional Tribunal that he has appealed to this court on the grounds that:—\\n\\n__paragraph__\\n1\\\\. “ The tribunal failed to critically evaluate the evidence.\\n\\n__paragraph__\\n2\\\\. The tribunal Erred in dismissing the Appeal.\\n\\n__paragraph__\\n3\\\\. The tribunal Erred in holding that the appellant was negligent.\\n\\n__paragraph__\\n4\\\\. The finding by the tribunal that the Appellant was confused and panicky and this caused the accident is not borne out by the evidence on record.\\n\\n__paragraph__\\n5\\\\. The Judgment was erroneous and not the result of proper resolution of the facts in issue since the tribunal failed to consider the several facts which were in favour of the appellant and which were sufficient to exonerate him from the charge.\\n\\n__paragraph__\\nThe facts of the case as alleged by the prosecution are that on 18/1/2001 at about 7.15 p.m, the appellant herein, Joseph Donkor of Union Transport Africa Ltd, Takoradi drove Scania Cement Articulated Tanker No. GT 7086 A loaded with cement from Takoradi to Acheampong near Tarkwa. Between Bronyibima and Yesumkwa along Cape Coast-Takoradi Road, accused drove into the lane of an on coming Mercedes Benz Car No. GW 2686 Q then being driven by one Michael Hackenberg, General Manager Construction pioneers (CP) and hit the Benz car which caught fire and burnt completely.\\n\\n__paragraph__\\nOne Doctor Spark who was with the driver on the Mercedes Benz sustained injuries. According to PW1, who was driving the Mercedes Benz Car, the Appellant tried to avoid hitting him in his lane so he swerved into his (Appellant’s) lane again but the Trailer of his truck fell down and hit his car in his lane.\\n\\n__paragraph__\\nThe fact that the Articulated Truck was driven into the lane of the Mercedes Benz was denied by the defence which contended that it was rather the driver of the Mercedes Benz who drove into the lane of the Truck.\\n\\n__paragraph__\\nCounsel for the Appellant at the hearing of the appeal, abandoned ground 2 of the appeal.\\n\\n__paragraph__\\nGrounds 1, 3 and 5 were argued together. Counsel submitted that the findings made by the court cannot be supported by the evidence.\\n\\n__paragraph__\\nThe Appellate tribunal dismissed the Appellant’s appeal because, as the Judgment of the Tribunal reads “We cannot agree more with the lower court in its observation above. We therefore hold that the trial court was right in its Judgment and we have no just cause to disturb it, the findings made by the trial court were supported by the evidence.”\\n\\n__paragraph__\\nThe trial court had found the appellant “negligent and careless”. That “he refused to keep a proper look out and in his own words, he never saw PW1’s Benz Car”.\\n\\n__paragraph__\\nCounsel had seriously argued before this court that the appellant was not careless and that what he did when confronted with imminent danger was reasonably necessary in the circumstances and cannot amount to negligence.\\n\\n__paragraph__\\nHe referred the Court to the case of ASIBI (HAUSA) VRS FRANCIS EFFAH, Court of Appeal, Civil Appeal NO. 33/69 of 26th February 1970 (unreported) referred to by P. K. Twumasi in his Criminal Law in Ghana p. 606.\\n\\n__paragraph__\\nCounsel submitted that the appellant was faced with imminent danger of running into the Toyota Land Cruiser which had overtaken another vehicle and had found itself in his lane. He applied his brakes to avoid fatalities.\\n\\n__paragraph__\\nAccording to the appellant himself this was when he got out of a curve. The legal position is that where a person is confronted with an emergency he cannot be expected to conduct himself in a way a reasonable and prudent man would do in ordinary Circumstances. His blameworthiness must be Judged by the peculiar and unusual situation.\\n\\n__paragraph__\\nSee the case of LONDON PASSENGER TRANSPORT BOARD VRS. UPSON \\\\[1949\\\\] A.C. 155, referred to in Twumasi’s Criminal Law in Ghana p.606.\\n\\n__paragraph__\\nAttached to this principle is a rider that where, however, the emergency was created by an earlier act of negligence by the person concerned he cannot escape liability for the consequences of the situation he created by his own negligent act. So in this case, was the situation in which the appellant found himself brought about by an earlier act of carelessness on his part?\\n\\n__paragraph__\\nAccording to the appellant himself, he had finished negotiating a curve on the road. The accident had happened late in the evening, about 7.15 p.m. and visibility was poor. PW2 told the trial court that he could not take measurements that night because of visibility.\\n\\n__paragraph__\\nFrom the sketch of the scene of accident, Exh “A”, the distance between where the appellant sighted vehicle No 2686Q to the point of impact measured 205”. The appellant did sign the sketch by way of approval in the presence of an independent witness. At the trial, even though he did not object to the tendering of the sketch in evidence, he denied that the point of impact as indicated on the sketch was the actual point of impact. He told the Court the point of impact was in his lane of traffic but not in the lane of traffic of PW1 as indicated on the sketch.\\n\\n__paragraph__\\nHis denial per se, did not render the sketch inadmissible as contended by Counsel in the trial court. The appellant did not raise any objection to the tendering of the statement. Even if he had raised an objection, its admissibility like a confession statement would have been decided on evidence only where the appellant had denied signing the sketch or that he had signed under duress. Where the objection is raised on the ground of inaccuracy, it must first be admitted before it can be evaluated. The weight to be attached to it is a question of fact. See the case of ASARE alias FANTI VRS THE STATE \\\\[1964\\\\] GLR 70. The appellant did not object to the distance between where he sighted PW1’s vehicle and where the two vehicles collided whether in his lane of traffic or that of the other vehicle.\\n\\n__paragraph__\\nAs to the lane of traffic in which the vehicle collided, the appellant in his own statement told the police it was in PW1’s lane. This was the statement taken a day after the accident. 10 days later, on 29/3/2001 when given the opportunity to make another statement, he relied on his former statement made on 19/3/2001. Counsel urged it upon this court not to attach any weight to the statement because the appellant was remanded in custody and had been denied medical care on the day of the accident and that the statement was taken the next morning.\\n\\n__paragraph__\\nI find this submission strange because one would have thought that having slept over night, the Appellant rather would have reflected on the events leading to the accident and would remember correctly how and where the accident happened. If what he had told the police in that statement was not correct, he had another opportunity on which he could have changed same.\\n\\n__paragraph__\\nLike the sketch, the statement was tendered without objection and the contents were not denied. The weight to be attached to it was a question of fact for the trial court. I therefore see no reason why this court should be called upon not to attach any weight to it, a duty reserved for the trial court which had evaluated the statement.\\n\\n__paragraph__\\nUnder Cross-examination, the Appellant was asked the following questions:\\n\\n__paragraph__\\nQ. “What time after the accident did you make your statement to the police”.\\n\\n__paragraph__\\nA. “After the Police went to take measurement the next day.\"\\n\\n__paragraph__\\nQ. “so the statement you gave the police and what you are saying now, which one is correct?\"\\n\\n__paragraph__\\nA. “what I am saying now is correct.”\\n\\n__paragraph__\\nQ. “so what ever you told the police is not correct, it is a lie, I mean your statement?”\\n\\n__paragraph__\\nA. “I spoke the truth to the police.”\\n\\n__paragraph__\\nHe did not at the trial say that he pointed at a different point of impact which the investigating officer had ignored in the sketch.\\n\\n__paragraph__\\nThe Appellant’s vehicle was a Scania Cement Bulk Tanker which at the time of the accident was loaded with cement. With the size of the vehicle and the load, the Appellant was under a duty to exercise a greater degree of care and attention a prudent and reasonable driver would do especially while negotiating a curve. If he had driven his vehicle with due care and attention required of him, he could have avoided the accident from the distance of 205 feet from where he first sighted the Mercedes Benz Car.\\n\\n__paragraph__\\nAt a speed of 97 k.m.p.h., under the High way Code, a driver should be able to brake from a distance of 180\", from where he first sights an on coming vehicle ….\\n\\n__paragraph__\\nEven driving at that speed would not be reasonable under the circumstances having regard to the size of the vehicle with the load, that portion of the road where the accident happened and the time of the day. I am very mindful of the fact that speed per se is not evidence of carelessness or negligence but from the appellant’s own evidence, when he applied his brake, he lost control of it and his vehicle started swerving from one lane to the other.\\n\\n__paragraph__\\nAccording to the report of the officer in charge of Vehicle Examination and Licensing Department who tested the Appellant’s vehicle after the accident, the brakes, steering and the Electrical Systems were in good working order prior to the accident.\\n\\n__paragraph__\\nThe position in which the appellant found himself was not the result of a Mechanical fault. The evidence does not indicate that the road was slippery at the time.\\n\\n__paragraph__\\nCounsel for the Appellant urged it upon this court that the point of impact is not a determining factor in deciding the issue of carelessness.\\n\\n__paragraph__\\nRather, the position of the law is that the point of impact alone, was not a proper yardstick for resolving issues of road traffic negligence, see HAUSA VS. THE REPUBLIC \\\\[1981\\\\] GLR 840 Twumasi J. (as he then was) in his book Criminal Law in Ghana p. 615 on police sketch of scene of accident, mentions the point of impact as one of the important positions for determining liability for negligent driving.\\n\\n__paragraph__\\nThe trial court held that, it was a crucial factor in the determination of the case before it and found that the point of impact was in the lane of traffic of PW1.\\n\\n__paragraph__\\nThe Appellant therefore is to be blamed for driving into the lane of traffic of PW1 as there is no clear evidence that PW1 who was in his lane, had ample means and opportunity to prevent the accident.\\n\\n__paragraph__\\nThe case of OWUSU VRS. COMMISSIONER OF POLICE \\\\[1963\\\\] 1 GLR p.113 is rather not in favour of the Appellant.\\n\\n__paragraph__\\nUnder Cross-examination, he told the court that he did not even see PW1’s Car ahead of him. In his statement he said he saw a vehicle overtaking PW1’s Car ahead of him. Where he cannot even be sure whether he saw PW1’s Car or not, one can safely say that the Appellant did not drive his vehicle with due care and attention.\\n\\n__paragraph__\\nThe Appellate Tribunal evaluated the evidence on record and came to the conclusion that the findings made by the trial Tribunal are supported by the evidence. This court cannot therefore disturb that finding.\\n\\n__paragraph__\\nIndeed in this appeal the Chief State Attorney submitted that the Judgment of the Regional Tribunal is supported by the record and called upon the Court to dismiss the appeal.\\n\\n__paragraph__\\nI will not agree with counsel for the Appellant that the Judgment of the Regional Tribunal is erroneous as same is not based on proper evaluation and resolution of the facts in issues.\\n\\n__paragraph__\\nThe finding that the Appellant became confused and panicky, and that this caused the accident, I must admit is not borne out by the evidence.\\n\\n__paragraph__\\nIn this appeal, counsel for the Appellant said nothing about the second count of Negligently causing Harm, which flows directly from the first count. Its fate depends upon the success or failure of the conviction against the first count as a result of which the person named in the charge sheet in the second count sustained the injury.\\n\\n__paragraph__\\nHaving found that the Appellant drove his vehicle without due care and attention, he must be held liable for Negligently causing Harm to the person named in the second count.\\n\\n__paragraph__\\nOn the totality of the evidence, the appeal against conviction fails and same is hereby dismissed.\\n\\n__paragraph__\\nR. C. OWUSU (MS)\\n\\n__paragraph__\\nJUSTICE OF APPEAL\\n\\n__paragraph__\\nWOOD, JA:\\n\\n__paragraph__\\nI agree.\\n\\n__paragraph__\\nG. T. WOOD (MRS.)\\n\\n__paragraph__\\nJUSTICE OF APPEAL\\n\\n__paragraph__\\nGBADEGBE, JA:\\n\\n__paragraph__\\nI also agree.\\n\\n__paragraph__\\nN. S. GBADEGBE\\n\\n__paragraph__\\nJUSTICE OF APPEAL']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting content into sections\n",
    "sections_list = [s.strip() for s in content.split(\"__section__\") if s.strip()]\n",
    "sections_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f082773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R.C. OWUSU, JA:',\n",
       " 'This is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast.',\n",
       " 'The appellant herein had been charge on two counts of careless driving contrary to Sec. 18(1) of R.T.O. 55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29).',\n",
       " 'He was arraigned before the Community Tribunal, Elmina in the Central Region, tried and found guilty on both Counts. He was convicted on both counts and sentenced to a fine of �200,000.00 or 4 months I.H.L in default. He paid the fine.',\n",
       " 'Dissatisfied with the conviction and sentence however, he appealed to the Regional Tribunal, Cape Coast on the grounds that:']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_paragraphs = []\n",
    "\n",
    "for section in sections_list:\n",
    "    paragraphs_in_section = section.split(\"__paragraph__\")[1:]  # Ignoring text before the first __paragraph__ marker\n",
    "    refined_paragraphs.extend([p.strip() for p in paragraphs_in_section if p.strip()])\n",
    "\n",
    "refined_paragraphs[:5]  # Displaying the first 5 refined paragraphs for a quick overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afac8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R.C. OWUSU, JA: This is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast. The appellant herein had been charge on two counts of careless driving contrary to Sec. 18(1) of R.T.O. 55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29). He was arraigned before the Community Tribunal, Elmina in the Central Region, tried and found guilty on both Counts. He was convicted on both counts and sentenced to a fine of �200,000.00 or 4 months I.H.L in default. He paid the fine. Dissatisfied with the conviction and sentence however, he appealed to the Regional Tribunal, Cape Coast on the grounds that: i. “The Judgment is not supported by the evidence on record. ii. The trial Court Erred in holding that the point of impact was '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining all the refined paragraphs into one passage\n",
    "combined_passage_refined = \" \".join(refined_paragraphs)\n",
    "combined_passage_refined[:1000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e62e88cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R.C',\n",
       " 'OWUSU, JA: This is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast',\n",
       " 'The appellant herein had been charge on two counts of careless driving contrary to Sec',\n",
       " '18(1) of R.T.O',\n",
       " '55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the combined passage into chunks of 5 sentences each\n",
    "sentences_refined = combined_passage_refined.split('. ')\n",
    "sentences_refined[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7cb98d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R.C. OWUSU, JA: This is an appeal against the Judgment of His Lordship Nana Barfour Adjei (Chairman) sitting with Messrs Eric Wood and George Amissah, Miss Cobbah-Yalley and Florence Dadzie as panel members delivered on 15/11/2001 at the Regional Tribunal Cape Coast. The appellant herein had been charge on two counts of careless driving contrary to Sec. 18(1) of R.T.O. 55/52 as amended by section 4 of Act 553 of 1998 and Negligently causing Harm contrary to section 72 of the Criminal Code of 1960 (Act 29).',\n",
       " 'He was arraigned before the Community Tribunal, Elmina in the Central Region, tried and found guilty on both Counts. He was convicted on both counts and sentenced to a fine of �200,000.00 or 4 months I.H.L in default. He paid the fine. Dissatisfied with the conviction and sentence however, he appealed to the Regional Tribunal, Cape Coast on the grounds that: i. “The Judgment is not supported by the evidence on record.',\n",
       " 'ii. The trial Court Erred in holding that the point of impact was in the lane of traffic of PW1. iii. The trial court failed to appreciate the defence of the Accused. iv.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_of_five_sentences_refined = []\n",
    "temp_chunk_refined = []\n",
    "\n",
    "for sentence in sentences_refined:\n",
    "    temp_chunk_refined.append(sentence)\n",
    "    if len(temp_chunk_refined) == 5:\n",
    "        chunks_of_five_sentences_refined.append(\". \".join(temp_chunk_refined) + \".\")\n",
    "        temp_chunk_refined = []\n",
    "\n",
    "# Adding any remaining sentences to the last chunk\n",
    "if temp_chunk_refined:\n",
    "    chunks_of_five_sentences_refined.append(\". \".join(temp_chunk_refined) + \".\")\n",
    "\n",
    "chunks_of_five_sentences_refined[:3]  # Displaying the first 3 chunks for a quick overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c646f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d653a655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booksReferredTo': [],\n",
       " 'caseId': {'number': None, 'type': None},\n",
       " 'casesReferredTo': [],\n",
       " 'combinedCounsel': ['JOHN MERCER FOR THE APPELLANT',\n",
       "  'AGBOLOSOO FOR THE RESPONDENT'],\n",
       " 'combinedParties': ['JOSEPH DONKOR v. THE REPUBLIC'],\n",
       " 'counsel': {'Plaintiff/Appellant': ['JOHN MERCER'],\n",
       "  'Defendant/Respondent': ['AGBOLOSOO']},\n",
       " 'court': {'location': {'city': 'ACCRA', 'country': 'GHANA'}, 'name': None},\n",
       " 'editorialNote': None,\n",
       " 'headNotes': None,\n",
       " 'indices': [],\n",
       " 'judgement': {'date': '2002-03-13T00:00:00.000Z',\n",
       "  'year': 2002,\n",
       "  'month': 'March',\n",
       "  'day': 13},\n",
       " 'judges': [],\n",
       " 'lawReportsCitations': [],\n",
       " 'mediaNeutralCitation': None,\n",
       " 'natureOfProceedings': None,\n",
       " 'partiesOfSuit': {'Plaintiff/Appellant': ['JOSEPH DONKOR'],\n",
       "  'Defendant/Respondent': ['THE REPUBLIC']},\n",
       " 'presidingJudge': 'OWUSU ANSAH (MS), JA',\n",
       " 'source': 'elibrary.jsg.gov.gh',\n",
       " 'sourceFile': '\\\\original_source_files\\\\Cases from 1993 - 2014\\\\2000\\\\COURT OF APPEAL\\\\JOSEPH DONKOR v. THE REPUBLIC.htm',\n",
       " 'statutesReferredTo': [],\n",
       " 'title': {'long': 'JOSEPH DONKOR v. THE REPUBLIC',\n",
       "  'short': 'JOSEPH DONKOR vs THE REPUBLIC'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 4: Extracting metadata from the accompanying metadata file\n",
    "\n",
    "with open(\"../Legal_Files/Corpus/kwame-legal-EL-1680770407105_Metadata.json\", \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5698eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/passage_metadata.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 5: Creating pairings of each extracted passage and the corresponding metadata\n",
    "\n",
    "passage_metadata_pairings = [{\"Passage\": passage, \"Metadata\": json.dumps(metadata)} \n",
    "                            for passage in chunks_of_five_sentences_refined]\n",
    "\n",
    "# Step 6: Writing the pairings to a CSV file\n",
    "\n",
    "csv_filename = \"data/passage_metadata.csv\"\n",
    "\n",
    "with open(csv_filename, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"Passage\", \"Metadata\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for pairing in passage_metadata_pairings:\n",
    "        writer.writerow(pairing)\n",
    "\n",
    "csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb0184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Process a folder containing pairs of .txt and .json files. Extract passages from the .txt files, \n",
    "    metadata from the .json files, and write pairings to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing the files.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Path to the generated CSV file.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_pairings = []\n",
    "    \n",
    "    # Get all .txt and .json files in the folder\n",
    "    txt_files = [f for f in os.listdir(folder_path) if f.endswith('_Technical.txt')]\n",
    "    json_files = [f.replace('_Technical.txt', '_Metadata.json') for f in txt_files]\n",
    "\n",
    "    for txt_file, json_file in zip(txt_files, json_files):\n",
    "        # Extract passages from .txt file\n",
    "        with open(os.path.join(folder_path, txt_file), \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "        sections_list = [s.strip() for s in content.split(\"__section__\") if s.strip()]\n",
    "        refined_paragraphs = []\n",
    "        for section in sections_list:\n",
    "            paragraphs_in_section = section.split(\"__paragraph__\")[1:]  # Ignoring text before the first __paragraph__ marker\n",
    "            refined_paragraphs.extend([p.strip() for p in paragraphs_in_section if p.strip()])\n",
    "        combined_passage_refined = \" \".join(refined_paragraphs)\n",
    "        sentences_refined = combined_passage_refined.split('. ')\n",
    "        chunks_of_five_sentences_refined = []\n",
    "        temp_chunk_refined = []\n",
    "        for sentence in sentences_refined:\n",
    "            temp_chunk_refined.append(sentence)\n",
    "            if len(temp_chunk_refined) == 5:\n",
    "                chunks_of_five_sentences_refined.append(\". \".join(temp_chunk_refined) + \".\")\n",
    "                temp_chunk_refined = []\n",
    "        if temp_chunk_refined:\n",
    "            chunks_of_five_sentences_refined.append(\". \".join(temp_chunk_refined) + \".\")\n",
    "        \n",
    "        # Extract metadata from .json file\n",
    "        with open(os.path.join(folder_path, json_file), \"r\", encoding=\"utf-8\") as metadata_file:\n",
    "            metadata = json.load(metadata_file)\n",
    "        \n",
    "        # Create pairings of passages and metadata\n",
    "        for passage in chunks_of_five_sentences_refined:\n",
    "            all_pairings.append({\"Passage\": passage, \"Metadata\": json.dumps(metadata)})\n",
    "    \n",
    "    # Write all_pairings to a CSV file\n",
    "    csv_filename = os.path.join(folder_path, \"passage_metadata.csv\")\n",
    "    with open(csv_filename, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"Passage\", \"Metadata\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for pairing in all_pairings:\n",
    "            writer.writerow(pairing)\n",
    "    \n",
    "    return csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c74c6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_output_path = process_folder(\"../Legal_Files/Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e8610a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Legal_Files/Corpus\\\\passage_metadata.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82cb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "532d3791",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79a1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "     ---------------------------------------- 7.6/7.6 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.0-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.1-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "     -------------------------------------- 295.0/295.0 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "     -------------------------------------- 173.4/173.4 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting packaging>=20.9\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.8.8-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.3-cp311-cp311-win_amd64.whl (266 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-10.0.1-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "     ------------------------------------ 123.8/123.8 kB 811.1 kB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, urllib3, typing-extensions, threadpoolctl, sympy, regex, pyyaml, pillow, packaging, numpy, networkx, MarkupSafe, joblib, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, scipy, requests, jinja2, click, torch, scikit-learn, nltk, huggingface-hub, transformers, torchvision, sentence-transformers\n",
      "  Running setup.py install for sentence-transformers: started\n",
      "  Running setup.py install for sentence-transformers: finished with status 'done'\n",
      "Successfully installed MarkupSafe-2.1.3 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.7 colorama-0.4.6 filelock-3.12.4 fsspec-2023.9.2 huggingface-hub-0.17.3 idna-3.4 jinja2-3.1.2 joblib-1.3.2 mpmath-1.3.0 networkx-3.1 nltk-3.8.1 numpy-1.26.0 packaging-23.1 pillow-10.0.1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 safetensors-0.3.3 scikit-learn-1.3.1 scipy-1.11.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.2.0 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 tqdm-4.66.1 transformers-4.33.2 typing-extensions-4.8.0 urllib3-2.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: sentence-transformers is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9f2f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TurnerZ\\Documents\\GitHub\\QueryQuill\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b673a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The model paraphrase-distilroberta-base-v1 is one of the recommended models from the SentenceTransformers \n",
    "library for generating sentence and paragraph embeddings. It's trained specifically for the purpose of \n",
    "paraphrasing, which means it can generate embeddings that capture the semantic meaning of the text.\n",
    "\n",
    "The model we chose provides a balanced trade-off between performance, speed, and size. Depending on the \n",
    "specific requirements (e.g., real-time search, deployment constraints), one might opt for a different model. \n",
    "\"\"\"\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754665ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_and_save(csv_input_path, csv_output_path):\n",
    "    # Load the model\n",
    "    model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "    \n",
    "    with open(csv_input_path, \"r\", encoding=\"utf-8\") as csvfile, open(csv_output_path, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        fieldnames = [\"Passage\", \"Metadata\", \"Embedding\"]\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            passage = row[\"Passage\"]\n",
    "            metadata = row[\"Metadata\"]\n",
    "            embedding = model.encode(passage, convert_to_tensor=True).tolist()\n",
    "            \n",
    "            writer.writerow({\n",
    "                \"Passage\": passage,\n",
    "                \"Metadata\": metadata,\n",
    "                \"Embedding\": embedding\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdcbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_input_path = \"../docs/passage_metadata.csv\" \n",
    "csv_output_path = \"../docs/passage_metadata_emb.csv\"\n",
    "generate_embeddings_and_save(csv_input_path, csv_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876d7ff",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ElasticSearch Index:\n",
    "An ElasticSearch index is like a database in traditional relational databases. It's a place where you store related documents and is defined by a name (like \"passage_metadata_emb\" in our example). \n",
    "Each document within an index is a collection of fields, which you can think of as columns in a traditional database table.\n",
    "\n",
    "Mapping:\n",
    "Mapping in ElasticSearch is the process of defining how a document and its fields are stored and indexed. It's akin to defining the schema for a database table in relational databases.\n",
    "\n",
    "For our task, we need to store passages, their metadata, and the embeddings we computed for them. Thus, our mapping will define the structure and types for these fields.\n",
    "\n",
    "Design of the Index:\n",
    "    Passage and Metadata Fields:\n",
    "        Type: text\n",
    "        These fields will store the actual content of the passages and their associated metadata. The text type allows ElasticSearch to tokenize the content, making it searchable using full-text search capabilities.\n",
    "    Embedding Field:\n",
    "        Type: dense_vector\n",
    "        This field will store the embeddings of the passages. Embeddings are high-dimensional vectors, and ElasticSearch provides a dense_vector data type to store and work with such vectors.\n",
    "        The dims parameter specifies the number of dimensions for the vector. Many transformer-based models, like distilroberta-base, produce embeddings of size 768. This is why we set dims to 768. However, \n",
    "        if you were to use a different model that produces embeddings of a different size, you would need to adjust this value accordingly.\n",
    "\n",
    "\n",
    "Purpose:\n",
    "The primary reason for this setup is to enable semantic search using ElasticSearch. By storing the embeddings (dense vectors) in ElasticSearch, we can later perform similarity searches. For instance, \n",
    "when a user submits a query, we can compute its embedding, and then search the ElasticSearch index to find the passages whose embeddings are most similar (in terms of cosine similarity) to the query's embedding.\n",
    "\n",
    "In summary, creating this index with the specified mapping allows us to efficiently store passages, their metadata, and embeddings in a structured manner, facilitating powerful and fast semantic \n",
    "search capabilities.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f92847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TurnerZ\\AppData\\Local\\Temp\\ipykernel_38500\\3630695091.py:2: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  es = Elasticsearch(\n",
      "C:\\Users\\TurnerZ\\AppData\\Local\\Temp\\ipykernel_38500\\3630695091.py:2: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "es = Elasticsearch(\n",
    "    hosts=[{\n",
    "        'host': 'passage-metadata-emb.es.us-central1.gcp.cloud.es.io',\n",
    "        'port': 9243, #default for secured Elasticsearch on Elastic Cloud.\n",
    "        'scheme': 'https',\n",
    "    }],\n",
    "    http_auth=('elastic', 'o2S5WT8BA7sUq2mQeKhOmcOZ'), \n",
    "    timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f27e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TurnerZ\\AppData\\Local\\Temp\\ipykernel_38500\\4153306498.py:16: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es_instance.indices.create(index=index_name, body=mapping)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Many transformer-based models, like distilroberta-base, produce embeddings of size 768. This is why we set dims to 768.\n",
    "\"\"\"\n",
    "\n",
    "def create_index(es_instance, index_name=\"passage_metadata_emb\"):\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Passage\": {\"type\": \"text\"},\n",
    "                \"Metadata\": {\"type\": \"text\"},\n",
    "                \"Embedding\": {\"type\": \"dense_vector\", \"dims\": 768}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    es_instance.indices.create(index=index_name, body=mapping)\n",
    "\n",
    "create_index(es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17aa1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def index_data_to_elasticsearch(es_instance, csv_file_path, index_name=\"passage_metadata_emb\"):\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        actions = []\n",
    "        for row in reader:\n",
    "            action = {\n",
    "                \"_index\": index_name,\n",
    "                \"_source\": {\n",
    "                    \"Passage\": row[\"Passage\"],\n",
    "                    \"Metadata\": row[\"Metadata\"],\n",
    "                    \"Embedding\": [float(x) for x in row[\"Embedding\"][1:-1].split(\",\")]  # Convert string representation of list to actual list\n",
    "                }\n",
    "            }\n",
    "            actions.append(action)\n",
    "\n",
    "        # Bulk index the data\n",
    "        helpers.bulk(es_instance, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11099ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"../docs/passage_metadata_emb.csv\"  \n",
    "index_data_to_elasticsearch(es, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d01b3",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b850da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_passages(es_instance, index_name, query_embedding, top_n=3):\n",
    "    # Use the script_score method to compute the cosine similarity\n",
    "    query_body = {\n",
    "        \"size\": top_n,\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\n",
    "                    \"match_all\": {}\n",
    "                },\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'Embedding') + 1.0\",\n",
    "                    \"params\": {\n",
    "                        \"query_vector\": query_embedding\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es_instance.search(index=index_name, body=query_body)\n",
    "    return response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fecad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results to CSV\n",
    "def save_results_to_csv(query, search_results, csv_file_path=\"questions_answers.csv\"):\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Question\", \n",
    "                         \"Passage 1\", \"Relevance Score 1\", \"Passage 1 Metadata\", \n",
    "                         \"Passage 2\", \"Relevance Score 2\", \"Passage 2 Metadata\", \n",
    "                         \"Passage 3\", \"Relevance Score 3\", \"Passage 3 Metadata\"])\n",
    "        \n",
    "        row = [query]\n",
    "        for hit in search_results:\n",
    "            row.extend([hit[\"_source\"][\"Passage\"], hit[\"_score\"], hit[\"_source\"][\"Metadata\"]])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcde7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user query\n",
    "user_query = \"What is the impact of constitutional law?\"\n",
    "query_embedding = model.encode(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for relevant passages\n",
    "es_instance = Elasticsearch([{'host': 'your_elasticsearch_url', 'port': 9243, 'use_ssl': True}])\n",
    "index_name = \"passage_index\"  # Assuming this is the name of your index\n",
    "search_results = search_similar_passages(es_instance, index_name, query_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796dd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "save_results_to_csv(user_query, search_results)\n",
    "\n",
    "# Return the path to the saved CSV\n",
    "csv_file_path = \"questions_answers.csv\"\n",
    "csv_file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
